{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8fsCpe_6QzL7"
      },
      "outputs": [],
      "source": [
        "!pip install pymupdf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "id": "_OeegAe_WZ4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openai_api_key = input(\"Enter your OpenAI API key: \");"
      ],
      "metadata": {
        "id": "uHpro7JzwRxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "import os\n",
        "\n",
        "client = OpenAI(\n",
        "    # This is the default and can be omitted\n",
        "    api_key=openai_api_key,\n",
        ")\n",
        "\n",
        "def query_gpt4(prompt, input, temperature=0.2):\n",
        "    \"\"\"\n",
        "    Sends a prompt to GPT-4 and retrieves the response with a specified temperature.\n",
        "\n",
        "    Parameters:\n",
        "        prompt (str): The input prompt for GPT-4.\n",
        "        temperature (float): Controls the randomness in the response, lower is more deterministic.\n",
        "\n",
        "    Returns:\n",
        "        str: The response from GPT-4.\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            messages=[\n",
        "                {\n",
        "                    \"role\": \"system\",\n",
        "                    \"content\": prompt,\n",
        "                },\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": input\n",
        "                }\n",
        "            ],\n",
        "            model=\"gpt-4-turbo\",\n",
        "        )\n",
        "        return response.choices[0].message.content\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "SFN0J1McWXB2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import fitz"
      ],
      "metadata": {
        "id": "nJxe4nImQ3lY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_path = \"DDIA.pdf\""
      ],
      "metadata": {
        "id": "f7vpqCfrRA6Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc = fitz.open(pdf_path)"
      ],
      "metadata": {
        "id": "eXAtMloNRHGE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_page, end_page = 8, 13"
      ],
      "metadata": {
        "id": "4QnO0x9mT5e-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pages = [doc.load_page(i) for i in range(start_page, end_page + 1)]"
      ],
      "metadata": {
        "id": "KjBUqY0_RIOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_texts = '\\n'.join([str(page.get_text()) for page in pages])"
      ],
      "metadata": {
        "id": "_2XV_fRzRI1_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_texts"
      ],
      "metadata": {
        "id": "Ev_iTConRNdv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bookSchema = \"\"\"\n",
        "type: object\n",
        "properties:\n",
        "  id:\n",
        "    type: string\n",
        "    description: The ID of the textbook.\n",
        "  title:\n",
        "    type: string\n",
        "    description: The title of the textbook.\n",
        "  chapters:\n",
        "    type: array\n",
        "    description: A list of chapters in the textbook.\n",
        "    items:\n",
        "      id:\n",
        "        type: string\n",
        "        description: The ID of the chapter.\n",
        "  metadata:\n",
        "    type: object\n",
        "    additionalProperties: true\n",
        "    description: Metadata for the textbook.\n",
        "\n",
        "required:\n",
        "  - id\n",
        "  - title\n",
        "  - chapters\"\"\"\n",
        "\n",
        "chapterSchema = \"\"\"\n",
        "type: object\n",
        "properties:\n",
        "  id:\n",
        "    type: string\n",
        "    description: The ID of the chapter.\n",
        "  title:\n",
        "    type: string\n",
        "    description: The title of the chapter.\n",
        "  range:\n",
        "    type: array\n",
        "    items:\n",
        "      type: integer\n",
        "    minItems: 2\n",
        "    maxItems: 2\n",
        "    description: The start and end pages of the chapter.\n",
        "  subchapters:\n",
        "    type: array\n",
        "    items:\n",
        "      id:\n",
        "        type: string\n",
        "        description: The ID of the subchapter.\n",
        "    description: A list of subchapters.\n",
        "  metadata:\n",
        "    type: object\n",
        "    additionalProperties: true\n",
        "    description: Metadata for the chapter.\n",
        "\n",
        "required:\n",
        "  - id\n",
        "  - title\n",
        "  - range\"\"\""
      ],
      "metadata": {
        "id": "tet4wO7oYQsR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaning_prompt_template = f\"\"\"\n",
        "You are given as input the table of contents of Designing Data-Intensive Applications. The text is scraped from a PDF file, so there are headers/footers like \"table of contents\" you have to ignore.\n",
        "Help me to clean this table of contents into a list of major chapters and subchapters, which may have subchapters of their own, each pointing to a page number.\n",
        "Chapters that aren't technical content like \"Preface\" or \"Glossary\" should be omitted.\n",
        "\n",
        "Clean it into the following YAML schema:\n",
        "Book shema:\n",
        "{bookSchema}\n",
        "\n",
        "Chapter schema:\n",
        "{chapterSchema}\n",
        "\n",
        "Don't worry about generating the IDs for now.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "nngs7slqRSPP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "precleaning_prompt_template = f\"\"\"\n",
        "You are given as input the table of contents of Designing Data-Intensive Applications. The text is scraped from a PDF file, so there are headers/footers like \"table of contents\" you have to ignore.\n",
        "Help me to clean this table of contents into a list of major chapters and subchapters.\n",
        "Chapters that aren't technical content like \"Preface\" or \"Glossary\" should be omitted.\n",
        "\n",
        "Print into the following example yaml format, always reproducing the page number following the chapter name.\n",
        "Make sure that the indentation is correct.\n",
        "\n",
        "If a chapter starts on page 107, it should read\n",
        "\n",
        "chapter name 107\n",
        "\n",
        "Example:\n",
        "\n",
        "- Major chapter name 1\n",
        "  - subchapter name 1\n",
        "    - subsubchapter name 3\n",
        "    - subsubchapter name 4\n",
        "  - subchapter name 6\n",
        "  - subchapter name 7\n",
        "- Major chapter name 9\n",
        "  - subchapter name 10\n",
        "  - subchapter name 12\"\"\""
      ],
      "metadata": {
        "id": "-GuAsHYdc2ih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = query_gpt4(\"hi\", \"hi there\")\n",
        "print(test)"
      ],
      "metadata": {
        "id": "k7ysY81fcccK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned = query_gpt4(precleaning_prompt_template, raw_texts)"
      ],
      "metadata": {
        "id": "mjCD6zpZTYla"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned"
      ],
      "metadata": {
        "id": "8o0egPfYTY6z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned = cleaned.replace(\"```yaml\\n\", \"\")\n",
        "cleaned = cleaned.replace(\"```\", \"\")"
      ],
      "metadata": {
        "id": "EWpQQunIa2F-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned"
      ],
      "metadata": {
        "id": "JTMTGQNRhmC5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "old_cleaned = \"\"\"\n",
        "- \"Foundations of Data Systems 3\"\n",
        "  - \"Reliable, Scalable, and Maintainable Applications 3\"\n",
        "    - \"Thinking About Data Systems 4\"\n",
        "    - Reliability 6\n",
        "    - Hardware Faults 7\n",
        "    - Software Errors 8\n",
        "    - Human Errors 9\n",
        "    - How Important Is Reliability? 10\n",
        "    - Scalability 10\n",
        "    - Describing Load 11\n",
        "    - Describing Performance 13\n",
        "    - Approaches for Coping with Load 17\n",
        "    - Maintainability 18\n",
        "    - Operability: Making Life Easy for Operations 19\n",
        "    - Simplicity: Managing Complexity 20\n",
        "    - Evolvability: Making Change Easy 21\n",
        "  - Summary 22\n",
        "  - Data Models and Query Languages 27\n",
        "    - Relational Model Versus Document Model 28\n",
        "    - The Birth of NoSQL 29\n",
        "    - The Object-Relational Mismatch 29\n",
        "    - Many-to-One and Many-to-Many Relationships 33\n",
        "    - Are Document Databases Repeating History? 36\n",
        "    - Relational Versus Document Databases Today 38\n",
        "    - Query Languages for Data 42\n",
        "    - Declarative Queries on the Web 44\n",
        "    - MapReduce Querying 46\n",
        "    - Graph-Like Data Models 49\n",
        "    - Property Graphs 50\n",
        "    - The Cypher Query Language 52\n",
        "    - Graph Queries in SQL 53\n",
        "    - Triple-Stores and SPARQL 55\n",
        "    - The Foundation: Datalog 60\n",
        "  - Summary 63\n",
        "  - Storage and Retrieval 69\n",
        "    - Data Structures That Power Your Database 70\n",
        "    - Hash Indexes 72\n",
        "    - SSTables and LSM-Trees 76\n",
        "    - B-Trees 79\n",
        "    - Comparing B-Trees and LSM-Trees 83\n",
        "    - Other Indexing Structures 85\n",
        "    - Transaction Processing or Analytics? 90\n",
        "    - Data Warehousing 91\n",
        "    - Stars and Snowflakes: Schemas for Analytics 93\n",
        "    - Column-Oriented Storage 95\n",
        "    - Column Compression 97\n",
        "    - Sort Order in Column Storage 99\n",
        "    - Writing to Column-Oriented Storage 101\n",
        "    - Aggregation: Data Cubes and Materialized Views 101\n",
        "  - Summary 103\n",
        "  - Encoding and Evolution 111\n",
        "    - Formats for Encoding Data 112\n",
        "    - Language-Specific Formats 113\n",
        "    - JSON, XML, and Binary Variants 114\n",
        "    - Thrift and Protocol Buffers 117\n",
        "    - Avro 122\n",
        "    - The Merits of Schemas 127\n",
        "    - Modes of Dataflow 128\n",
        "    - Dataflow Through Databases 129\n",
        "    - Dataflow Through Services: REST and RPC 131\n",
        "    - Message-Passing Dataflow 136\n",
        "  - Summary 139\n",
        "- Distributed Data 151\n",
        "  - Replication 151\n",
        "    - Leaders and Followers 152\n",
        "    - Synchronous Versus Asynchronous Replication 153\n",
        "    - Setting Up New Followers 155\n",
        "    - Handling Node Outages 156\n",
        "    - Implementation of Replication Logs 158\n",
        "    - Problems with Replication Lag 161\n",
        "    - Reading Your Own Writes 162\n",
        "    - Monotonic Reads 164\n",
        "    - Consistent Prefix Reads 165\n",
        "    - Solutions for Replication Lag 167\n",
        "    - Multi-Leader Replication 168\n",
        "    - Use Cases for Multi-Leader Replication 168\n",
        "    - Handling Write Conflicts 171\n",
        "    - Multi-Leader Replication Topologies 175\n",
        "    - Leaderless Replication 177\n",
        "    - Writing to the Database When a Node Is Down 177\n",
        "    - Limitations of Quorum Consistency 181\n",
        "    - Sloppy Quorums and Hinted Handoff 183\n",
        "    - Detecting Concurrent Writes 184\n",
        "  - Summary 192\n",
        "  - Partitioning 199\n",
        "    - Partitioning and Replication 200\n",
        "    - Partitioning of Key-Value Data 201\n",
        "    - Partitioning by Key Range 202\n",
        "    - Partitioning by Hash of Key 203\n",
        "    - Skewed Workloads and Relieving Hot Spots 205\n",
        "    - Partitioning and Secondary Indexes 206\n",
        "    - Partitioning Secondary Indexes by Document 206\n",
        "    - Partitioning Secondary Indexes by Term 208\n",
        "    - Rebalancing Partitions 209\n",
        "    - Strategies for Rebalancing 210\n",
        "    - Operations: Automatic or Manual Rebalancing 213\n",
        "    - Request Routing 214\n",
        "    - Parallel Query Execution 216\n",
        "  - Summary 216\n",
        "  - Transactions 221\n",
        "    - The Slippery Concept of a Transaction 222\n",
        "    - The Meaning of ACID 223\n",
        "    - Single-Object and Multi-Object Operations 228\n",
        "    - Weak Isolation Levels 233\n",
        "    - Read Committed 234\n",
        "    - Snapshot Isolation and Repeatable Read 237\n",
        "    - Preventing Lost Updates 242\n",
        "    - Write Skew and Phantoms 246\n",
        "    - Serializability 251\n",
        "    - Actual Serial Execution 252\n",
        "    - Two-Phase Locking (2PL) 257\n",
        "    - Serializable Snapshot Isolation (SSI) 261\n",
        "  - Summary 266\n",
        "  - The Trouble with Distributed Systems 273\n",
        "    - Faults and Partial Failures 274\n",
        "    - Cloud Computing and Supercomputing 275\n",
        "    - Unreliable Networks 277\n",
        "    - Network Faults in Practice 279\n",
        "    - Detecting Faults 280\n",
        "    - Timeouts and Unbounded Delays 281\n",
        "    - Synchronous Versus Asynchronous Networks 284\n",
        "    - Unreliable Clocks 287\n",
        "    - Monotonic Versus Time-of-Day Clocks 288\n",
        "    - Clock Synchronization and Accuracy 289\n",
        "    - Relying on Synchronized Clocks 291\n",
        "    - Process Pauses 295\n",
        "    - Knowledge, Truth, and Lies 300\n",
        "    - The Truth Is Defined by the Majority 300\n",
        "    - Byzantine Faults 304\n",
        "    - System Model and Reality 306\n",
        "  - Summary 310\n",
        "  - Consistency and Consensus 321\n",
        "    - Consistency Guarantees 322\n",
        "    - Linearizability 324\n",
        "    - What Makes a System Linearizable? 325\n",
        "    - Relying on Linearizability 330\n",
        "    - Implementing Linearizable Systems 332\n",
        "    - The Cost of Linearizability 335\n",
        "    - Ordering Guarantees 339\n",
        "    - Ordering and Causality 339\n",
        "    - Sequence Number Ordering 343\n",
        "    - Total Order Broadcast 348\n",
        "    - Distributed Transactions and Consensus 352\n",
        "    - Atomic Commit and Two-Phase Commit (2PC) 354\n",
        "    - Distributed Transactions in Practice 360\n",
        "    - Fault-Tolerant Consensus 364\n",
        "    - Membership and Coordination Services 370\n",
        "  - Summary 373\n",
        "- Derived Data 389\n",
        "  - Batch Processing 389\n",
        "    - Batch Processing with Unix Tools 391\n",
        "    - Simple Log Analysis 391\n",
        "    - The Unix Philosophy 394\n",
        "    - MapReduce and Distributed Filesystems 397\n",
        "    - MapReduce Job Execution 399\n",
        "    - Reduce-Side Joins and Grouping 403\n",
        "    - Map-Side Joins 408\n",
        "    - The Output of Batch Workflows 411\n",
        "    - Comparing Hadoop to Distributed Databases 414\n",
        "    - Beyond MapReduce 419\n",
        "    - Materialization of Intermediate State 419\n",
        "    - Graphs and Iterative Processing 424\n",
        "    - High-Level APIs and Languages 426\n",
        "  - Summary 429\n",
        "  - Stream Processing 439\n",
        "    - Transmitting Event Streams 440\n",
        "    - Messaging Systems 441\n",
        "    - Partitioned Logs 446\n",
        "    - Databases and Streams 451\n",
        "    - Keeping Systems in Sync 452\n",
        "    - Change Data Capture 454\n",
        "    - Event Sourcing 457\n",
        "    - State, Streams, and Immutability 459\n",
        "    - Processing Streams 464\n",
        "    - Uses of Stream Processing 465\n",
        "    - Reasoning About Time 468\n",
        "    - Stream Joins 472\n",
        "    - Fault Tolerance 476\n",
        "  - Summary 479\n",
        "  - The Future of Data Systems 489\n",
        "    - Data Integration 490\n",
        "    - Combining Specialized Tools by Deriving Data 490\n",
        "    - Batch and Stream Processing 494\n",
        "    - Unbundling Databases 499\n",
        "    - Composing Data Storage Technologies 499\n",
        "    - Designing Applications Around Dataflow 504\n",
        "    - Observing Derived State 509\n",
        "    - Aiming for Correctness 515\n",
        "    - The End-to-End Argument for Databases 516\n",
        "    - Enforcing Constraints 521\n",
        "    - Timeliness and Integrity 524\n",
        "    - Trust, but Verify 528\n",
        "    - Doing the Right Thing 533\n",
        "    - Predictive Analytics 533\n",
        "    - Privacy and Tracking 536\n",
        "  - Summary 543\"\"\""
      ],
      "metadata": {
        "id": "QD9CwGL5ijWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Chapter:\n",
        "    def __init__(self, title, firstPage, subchapters):\n",
        "        self.id = id\n",
        "        self.title = title\n",
        "        self.firstPage = firstPage\n",
        "        self.subchapters = subchapters\n",
        "\n",
        "    def setLastPage(self, lastPage):\n",
        "        self.lastPage = lastPage\n",
        "        self.range = [self.firstPage, lastPage]\n",
        "\n"
      ],
      "metadata": {
        "id": "oCC7eMT9iltd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse(str_list, index = 0):\n",
        "    \"\"\"\n",
        "    Input: list of strings in a yaml-like format\n",
        "    Output: (list of Chapter objects, index of last chapter)\n",
        "    \"\"\"\n",
        "    def parse_chapter_info(string):\n",
        "        \"\"\"\n",
        "        returns (title, firstPage, indentation)\n",
        "        \"\"\"\n",
        "        # print(\"parsing\", string)\n",
        "        indentation = 0\n",
        "        while string[indentation] == \" \":\n",
        "            indentation += 1\n",
        "\n",
        "        number_start = len(string) - 1\n",
        "        while string[number_start-1].isnumeric():\n",
        "            number_start -= 1\n",
        "        title = string[indentation+2:number_start].strip()\n",
        "        # print(string, number_start, string[number_start:].strip())\n",
        "        firstPage = int(string[number_start:].strip())\n",
        "        return title, firstPage, indentation\n",
        "\n",
        "    chapters = []\n",
        "    while index < len(str_list):\n",
        "        string = str_list[index]\n",
        "        title, firstPage, indentation = parse_chapter_info(string)\n",
        "        index += 1\n",
        "        if index < len(str_list) and parse_chapter_info(str_list[index])[2] > indentation:\n",
        "            subchapters, index = parse(str_list, index)\n",
        "        else:\n",
        "            subchapters = []\n",
        "        chapters.append(Chapter(title, firstPage, subchapters))\n",
        "        if index < len(str_list) and parse_chapter_info(str_list[index])[2] < indentation:\n",
        "            break\n",
        "    return chapters, index\n",
        "\n",
        "\n",
        "\n",
        "cleanedList = list(filter(lambda x: x != \"\", cleaned.split('\\n')))\n",
        "chapters, index = parse(cleanedList)\n",
        "print(chapters)"
      ],
      "metadata": {
        "id": "uEQ0hdWGhVdb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for chapter in chapters:\n",
        "    print(chapter.title, chapter.firstPage)"
      ],
      "metadata": {
        "id": "YB2PQ_s5hxjL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def setPageRanges(chapters, lastPage=543):\n",
        "    for idx, chapter in reversed(list(enumerate(chapters))):\n",
        "        chapter.setLastPage(lastPage)\n",
        "        lastPage = chapters[idx].firstPage\n",
        "        setPageRanges(chapter.subchapters, lastPage)\n",
        "\n",
        "setPageRanges(chapters)"
      ],
      "metadata": {
        "id": "oZX1eYURoC3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for chapter in chapters:\n",
        "    print(chapter.title, chapter.range)\n",
        "for subchapter in chapters[0].subchapters:\n",
        "    print(subchapter.title, subchapter.range)"
      ],
      "metadata": {
        "id": "n1lilcUxpnFG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BOOK_OFFSET = 22"
      ],
      "metadata": {
        "id": "ZQw29dFxp1n-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Print the parsed AST to YAML!!!"
      ],
      "metadata": {
        "id": "3feJCRJ3qtyB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install shortuuid"
      ],
      "metadata": {
        "id": "NExyGhqnrh7o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shortuuid\n",
        "import yaml"
      ],
      "metadata": {
        "id": "zSonzIz-roCR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def random_uuid():\n",
        "    return shortuuid.uuid()[:6]\n",
        "\n",
        "def chapter_id():\n",
        "    return \"chapter-\" + random_uuid()\n",
        "\n",
        "def book_id():\n",
        "    return \"book-\" + random_uuid()\n",
        "\n",
        "def subchapter_id(subchapter):\n",
        "    return random_uuid()\n",
        "\n",
        "book_id()"
      ],
      "metadata": {
        "id": "mHTDLR9nqBH6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bookDict = {\n",
        "    \"id\": book_id(),\n",
        "    \"title\": \"Designing Data-Intensive Applications\",\n",
        "    \"chapters\": [],\n",
        "    \"metadata\": {\n",
        "        \"authors\": [\"Martin Kleppmann\"],\n",
        "        \"publisher\": \"Springer\",\n",
        "        \"date\": \"2019\",\n",
        "        \"stars\": 1,\n",
        "        \"image\": \"https://m.media-amazon.com/images/I/91JAIKQUkYL._AC_UF1000,1000_QL80_.jpg\"\n",
        "    }\n",
        "}\n"
      ],
      "metadata": {
        "id": "KxjhIMVfrX9R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getChapterDicts(chapters, bookFrom, depth=1):\n",
        "    chapterDicts = []\n",
        "    for chapter in chapters:\n",
        "        subChapterDicts = getChapterDicts(chapter.subchapters, bookFrom, depth+1)\n",
        "        chapterDict = {\n",
        "            \"id\": chapter_id(),\n",
        "            \"title\": chapter.title,\n",
        "            \"range\": [chapter.range[0] + BOOK_OFFSET, chapter.range[1] + BOOK_OFFSET],\n",
        "            \"subchapters\": [subDict[\"id\"] for subDict in subChapterDicts if subDict[\"metadata\"][\"depth\"] == depth + 1],\n",
        "            \"metadata\": {\n",
        "                \"book\": bookFrom,\n",
        "                \"depth\": depth\n",
        "            }\n",
        "        }\n",
        "        chapterDicts.append(chapterDict)\n",
        "        chapterDicts.extend(subChapterDicts)\n",
        "    return chapterDicts\n",
        "\n",
        "chapterDicts = getChapterDicts(chapters, bookDict[\"id\"])"
      ],
      "metadata": {
        "id": "DYFLb2f1uFff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bookDict[\"chapters\"] = [chapterDict[\"id\"] for chapterDict in chapterDicts if chapterDict[\"metadata\"][\"depth\"] == 1]"
      ],
      "metadata": {
        "id": "1ca2hM_xvRWr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(yaml.dump(bookDict))"
      ],
      "metadata": {
        "id": "VudbWK2xvPZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(yaml.dump(chapterDicts))"
      ],
      "metadata": {
        "id": "qvkdqfl3vWyk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kgEt8gCovvTL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}